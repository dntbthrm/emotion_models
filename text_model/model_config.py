MAX_VOCAB_SIZE = 20000  # Размер словаря токенизатора
MAX_SEQUENCE_LENGTH = 20  # Максимальная длина текста (обрезка или паддинг)
EMBEDDING_DIM = 128  # Размерность эмбеддингов слов 256
LSTM_UNITS = 128  # Количество нейронов в LSTM-слое
BATCH_SIZE = 128  # Размер мини-батча 32
EPOCHS = 20  # Количество эпох обучения
