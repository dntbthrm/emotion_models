MAX_VOCAB_SIZE = 20000  # Размер словаря токенизатора
MAX_SEQUENCE_LENGTH = 100  # Максимальная длина текста (обрезка или паддинг)
EMBEDDING_DIM = 256  # Размерность эмбеддингов слов
LSTM_UNITS = 128  # Количество нейронов в LSTM-слое
BATCH_SIZE = 32  # Размер мини-батча
EPOCHS = 50  # Количество эпох обучения
