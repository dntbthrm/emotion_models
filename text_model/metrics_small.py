import numpy as np
import pickle

import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

from text_model.TextPreprocessor import BASIC_EMOTIONS

df = pd.read_csv('../../dataset/ru-go-emotions-preprocessed_v8.csv')
#print(df[BASIC_EMOTIONS].values)
# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
#X_test = np.load("model_data/X_test_small.npy")
#y_test1 = np.load("train_test_data/y_test_small.npy")
tf.config.set_visible_devices([], 'GPU')
X_test = np.load('sran_X_test.npy')
y_test = np.load('sran_y_test.npy')
'''X_test = np.load('v10_X_val.npz')['arr_0']
y_test = np.load('v10_y_val.npz')['arr_0']'''
#X_test = np.load("train_test_data/X_test_small.npy")
#y_test = np.load("train_test_data/y_test_small.npy")
print(y_test)
# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = tf.keras.models.load_model("sran_model_v1.keras")
#model = tf.keras.models.load_model("emotion_model_small_v2.keras")
# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
#with open("train_test_data/label_to_index_small.pkl", "rb") as f:
with open("v6/label_to_index_small.pkl", "rb") as f:
    label_classes = pickle.load(f)

print(BASIC_EMOTIONS)
# –û–±—Ä–∞—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å {–∏–Ω–¥–µ–∫—Å: —ç–º–æ—Ü–∏—è}
#index_to_label = {idx: label for idx, label in enumerate(label_classes)}


# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
y_pred_probs = model.predict(X_test, verbose=0)
print(X_test.shape)
print(y_pred_probs.shape)
y_pred = (y_pred_probs >= 0.4).astype(int) # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤


#y_true = np.argmax(y_test, axis=1)  # –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
#print(y_true)
y_true = y_test
print(y_pred)
#y_true = y_test
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ y_true:", np.unique(y_true))
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ y_pred:", np.unique(y_pred))

# –í—ã–≤–æ–¥ –æ—Ç—á—ë—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏
report = classification_report(
    y_true,
    y_pred,
    target_names=[BASIC_EMOTIONS[i] for i in range(len(BASIC_EMOTIONS))],
    labels=np.arange(7)  # –í—Å–µ –∫–ª–∞—Å—Å—ã –æ—Ç 0 –¥–æ N-1
)


print("üîç –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏:\n")
print(report)

# ======= –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ =======

# 1Ô∏è‚É£ –ì—Ä–∞—Ñ–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ (accuracy) –∏ –ø–æ—Ç–µ—Ä—å (loss) –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
history = np.load("data_arrays/training_history_small_v3_improved1.npy", allow_pickle=True).item()

plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history["accuracy"], label="Train Accuracy")
plt.plot(history["val_accuracy"], label="Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("–ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏")
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history["loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("–ì—Ä–∞—Ñ–∏–∫ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å")
plt.legend()

#plt.savefig("images/accuracy_loss_small_v3.png")

# 2Ô∏è‚É£ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (confusion matrix)
'''conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=[index_to_label[i] for i in range(len(index_to_label))],
            yticklabels=[index_to_label[i] for i in range(len(index_to_label))])
plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
plt.ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix)")'''
#plt.savefig("images/confusion_matrix_small_v3.png")
